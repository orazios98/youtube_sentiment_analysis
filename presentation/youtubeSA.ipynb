{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Youtube Sentiment Analysis\n",
    "\n",
    "## <center> Progetto per il corso di <br> TECHNOLOGIES FOR ADVANCED PROGRAMMING\n",
    "\n",
    "### <center>Orazio Sciuto\n",
    "### <center>Universit√† degli Studi di Catania <br> Corso di Laurea Magistrale in Informatica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The project\n",
    "\n",
    "The main goal of this project is to provide moderators of youtube channels with a simple and powerful tool to be able to analyze reactions to posted videos in real time using *Sentiment Analysis*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How?\n",
    "\n",
    "The goal is accomplished by building a data pipeline using Docker and some of the leading Big data management technologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why?\n",
    "\n",
    "There are more and more cases of videos being filled with negative comments even for reasons outside the video itself\n",
    "\n",
    "![Alt text](mum.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Project workflow\n",
    "\n",
    "- Ingestion: using the Youtube API we can retrieve comments from a video and send it to Logstash\n",
    "- Streaming: using Kafka we can stream the comments to a Spark cluster\n",
    "- Processing: using Spark we can process the comments and extract the sentiment\n",
    "- Indexing: using Elasticsearch we can index the comments and their sentiment\n",
    "- Visualization: using Kibana we can visualize the comments and their sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Alt text](image-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Source\n",
    "\n",
    "### Youtube\n",
    "\n",
    "YouTube is an American online video sharing and social media platform headquartered in San Bruno, California, United States. Accessible worldwide, it was launched on February 14, 2005. It is owned by Google and is the second most visited website, after Google Search. YouTube has more than 2.5 billion monthly users, who collectively watch more than one billion hours of videos each day.As of May 2019, videos were being uploaded at a rate of more than 500 hours of content per minute.\n",
    "\n",
    "(Wikipedia)[https://en.wikipedia.org/wiki/YouTube]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Alt text](image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Ingestion\n",
    "\n",
    "1. **Python Script**\n",
    "    - Youtube Data Api V3\n",
    "    - Check Video in the channel\n",
    "    - Polling and filter new comments\n",
    "    - Send to logstash using socket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "2. **Logstash**\n",
    "    - Retrieve data using TCP plugin and send it to Kafka in the topic *youtube*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Youtube Data Api V3 - A small demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'youtube_api'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\osciu\\Documents\\TAP\\progettoTAPFeel_IT\\presentation\\youtubeSA.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/osciu/Documents/TAP/progettoTAPFeel_IT/presentation/youtubeSA.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39myoutube_api\u001b[39;00m \u001b[39mimport\u001b[39;00m YouTubeDataAPI\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/osciu/Documents/TAP/progettoTAPFeel_IT/presentation/youtubeSA.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m api_key \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInsert your API key: \u001b[39m\u001b[39m\"\u001b[39m);\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/osciu/Documents/TAP/progettoTAPFeel_IT/presentation/youtubeSA.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m yt \u001b[39m=\u001b[39m YouTubeDataAPI(api_key)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'youtube_api'"
     ]
    }
   ],
   "source": [
    "from youtube_api import YouTubeDataAPI\n",
    "\n",
    "api_key = input(\"Insert your API key: \");\n",
    "yt = YouTubeDataAPI(api_key)\n",
    "VIDEO_URL = input(\"Insert the video URL: \");\n",
    "comments = yt.get_video_comments(VIDEO_URL, order_by_time=True)\n",
    "print(\"Number of comments: \", len(comments))\n",
    "print(comments[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Streaming\n",
    "\n",
    " Streaming involves the continuous and real-time transmission of data from its source to a destination.\n",
    "\n",
    "**Apache Kafka**\n",
    "\n",
    "Apache Kafka is an open-source, distributed event streaming platform that is used for building real-time data pipelines and streaming applications. It provides a highly scalable and fault-tolerant way to publish and subscribe to data streams, making it ideal for processing and transmitting large volumes of data in real-time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Processing\n",
    "\n",
    "Processing refers to the manipulation, transformation, and analysis of data to extract meaningful insights or perform specific tasks. This step can include data cleansing, aggregation, and computations like **Sentiment Analysis**\n",
    "\n",
    "**Apache Spark**\n",
    "\n",
    "Apache Spark is an open-source distributed general-purpose cluster-computing framework. Spark provides an interface for programming entire clusters with implicit data parallelism and fault tolerance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![image.png](kafkatime.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "Sentiment analysis is the interpretation and classification of emotions (positive, negative and neutral) within text data using text analysis techniques. Sentiment analysis allows businesses to identify customer sentiment toward products, brands or services in online conversations and feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Spark MLlib or something else?**\n",
    "\n",
    "- Use SparkMLlib is for sure the fastest option for italian comments, but it should be trained with a lot of data to be able to classify correctly.\n",
    "- Other possible solutions are to use a python library like Vader but in this case the problem is that Vader is not able to classify Italian comments and so we need to translate them into English with all the problems that this can bring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![MlLib_bleah](mllib_not_work.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MlLib_bleah](not_ml.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demo Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Not fully satisfied with the result with MlLib, I tried something better.\n",
    "\n",
    "And finally I found: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**FEEL-IT: Emotion and Sentiment Classification for the Italian Language**\n",
    "\n",
    "Official docs [here](https://github.com/MilaNLProc/feel-it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Python311\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from feel_it import EmotionClassifier, SentimentClassifier\n",
    "\n",
    "emotion_classifier = EmotionClassifier()\n",
    "print(emotion_classifier.predict([\"sono molto felice\", \n",
    "                                  \"ma che cavolo vuoi\", \n",
    "                                  \"sono molto triste\"]))\n",
    "\n",
    "sentiment_classifier = SentimentClassifier()\n",
    "print(sentiment_classifier.predict([\"sono molto felice\", \n",
    "                                    \"ma che cavolo vuoi\", \n",
    "                                    \"sono molto triste\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Python311\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from feel_it import EmotionClassifier, SentimentClassifier\n",
    "\n",
    "sentiment_classifier = SentimentClassifier()\n",
    "emotion_classifier = EmotionClassifier()\n",
    "\n",
    "positive_comment = \"Video veramente ottimo, mi √® piaciuto molto!\"\\\n",
    "                \"Spero che continui su questa strada, sei bravo!\"\n",
    "negative_comment = \"Video brutto, non mi √® piaciuto per niente!\"\\\n",
    "        \"Spero che non continui su questa strada, non sei bravo!\"\n",
    "\n",
    "print(emotion_classifier.predict([positive_comment, negative_comment]))\n",
    "print(sentiment_classifier.predict([positive_comment, negative_comment]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Python311\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "![image.png](feelit.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Indexing\n",
    "\n",
    "Indexing involves creating structured references to the data, making it faster and more efficient to search and retrieve information. It's commonly used in databases and search engines. \n",
    "\n",
    "This is done using\n",
    "\n",
    "**Elasticsearch**\n",
    "\n",
    "Elasticsearch is a search engine based on the Lucene library. It provides a distributed, multitenant-capable full-text search engine with an HTTP web interface and schema-free JSON documents. Elasticsearch is developed in Java and is released as open source under the terms of the Apache License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![image.png](elastic.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Visualization\n",
    "\n",
    "Visualization is the graphical representation of information and data. By using visual elements like charts, graphs, and maps, data visualization tools provide an accessible way to see and understand trends, outliers, and patterns in data. \n",
    "\n",
    "This is done using\n",
    "\n",
    "**Kibana**\n",
    "\n",
    "Kibana is an open source data visualization dashboard for Elasticsearch. It provides visualization capabilities on top of the content indexed on an Elasticsearch cluster. Users can create bar, line and scatter plots, or pie charts and maps on top of large volumes of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![mllib_dash.png](kibana_last.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![final](final.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Thanks for the attention!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
